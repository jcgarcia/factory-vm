# Session Context - Factory VM Bug Fixes
**Date:** November 18, 2025 21:40  
**Duration:** ~2 hours  
**Focus:** Installation script debugging and fixes

---

## Quick Summary

Found and fixed three critical bugs in Factory VM installation:
1. PID file ownership issue (root-owned, user can't read)
2. Docker status check using wrong user
3. MOTD creation shell compatibility

All fixes committed (e8da79ebb). **Next step: Fresh installation test to verify fixes work.**

---

## What Happened This Session

### Starting Point
- User reported installation didn't complete successfully
- Missing credentials file, installation log issues
- MOTD not created
- Status script showing permission errors

### Investigation
1. Found credentials creation code exists but wasn't executing
2. Root cause: `set -euo pipefail` causes script to exit on any error
3. Applied defensive fixes for undefined variables
4. Ran fresh installation with logging to `~/logs/`

### Fresh Installation Results
- ‚úÖ Installation completed (18m 44s)
- ‚úÖ Credentials file created
- ‚ö†Ô∏è Two warnings: "Failed to create welcome banner", "Jenkins CLI test failed"
- ‚úÖ Manually verified Jenkins CLI works despite warning
- ‚úÖ Manually created MOTD (works fine)

### New Issue Discovered
User ran `status-factory.sh` ‚Üí showed "VM is not running" despite QEMU clearly running

**Root cause:** Status script can't read root-owned PID file

### Solutions Discussed
User identified two options:
1. Change ownership of PID file
2. Use sudo to read PID file

**Decision:** Use both approaches:
- Status script uses sudo to read PID file
- Start script fixes ownership after QEMU starts
- Docker check uses foreman@localhost with sudo

---

## Files Modified

### 1. setup-factory-vm.sh (Commit: e8da79ebb)

**Line ~1791:** MOTD creation
```bash
# Force bash shell for Alpine compatibility
ssh root@localhost 'bash -s' << 'MOTD_SCRIPT'
```

**Line ~1964:** Start script PID ownership fix
```bash
sudo qemu-system-aarch64 ... -pidfile "${PID_FILE}"
# Fix ownership immediately
[ -f "${PID_FILE}" ] && sudo chown ${USER}:${USER} "${PID_FILE}"
```

**Line ~2024-2060:** Status script generation
```bash
# Read PID with sudo fallback
PID=$(sudo cat "$PID_FILE" 2>/dev/null || cat "$PID_FILE" 2>/dev/null)

# Fallback to pgrep if PID file unreadable
if pgrep -f "qemu-system-aarch64.*factory" >/dev/null 2>&1; then
    PID=$(pgrep -f "qemu-system-aarch64.*factory" | head -1)
fi
```

**Line ~2114:** Docker status check
```bash
# Changed from root@localhost to foreman@localhost
ssh ... foreman@localhost "sudo docker ps --format 'table {{.Names}}\t{{.Status}}'"
```

### 2. CURRENT-STATUS.md
- Completely updated with test results
- Documented all issues and fixes
- Added next steps for fresh installation test

### 3. FactoryVM-Sprint2-Status-Nov18.md (NEW)
- Session summary
- Technical details of all fixes
- Testing checklist
- Next actions required

---

## Current State

### Running VM
- **QEMU PID:** 3062025 (running as root)
- **Location:** `/home/jcgarcia/vms/factory/`
- **Status:** Functional with manual fixes applied
- **Installation:** Nov 18, 20:57 (18m 44s)

### Temporary Fixes Applied to Current VM
‚ö†Ô∏è These are manual workarounds - not from automated installation:

1. **PID file:** Created manually with `echo "3062025" > factory.pid`
2. **Status script:** Manually replaced with fixed version
3. **MOTD:** Manually created via SSH

### Why Manual Fixes Were Needed
The test installation ran BEFORE fixes were committed to setup-factory-vm.sh:
- Timeline: Installation started ‚Üí bugs discovered ‚Üí fixes applied ‚Üí installation completed
- Generated files (status script, start script) captured old code
- Current VM has old versions of generated scripts

### Files Generated by Current Installation
```
~/vms/factory/
‚îú‚îÄ‚îÄ start-factory.sh      # OLD version (no PID ownership fix)
‚îú‚îÄ‚îÄ status-factory.sh     # OLD version (manually replaced)
‚îú‚îÄ‚îÄ stop-factory.sh       # OK
‚îî‚îÄ‚îÄ factory.pid           # Created manually
```

---

## Technical Details

### Issue 1: PID File Ownership

**Problem:**
- QEMU needs sudo to bind port 443 (HTTPS)
- `sudo qemu-system-aarch64 -pidfile ...` creates root-owned file
- Normal user cannot read root-owned files
- Status script fails: "Permission denied"

**Why This Matters:**
```bash
# Without fix:
ls -la factory.pid
# -rw-r--r-- root root factory.pid

cat factory.pid
# cat: factory.pid: Permission denied

# With fix:
ls -la factory.pid
# -rw-r--r-- jcgarcia jcgarcia factory.pid

cat factory.pid
# 3062025
```

**Solution:**
```bash
# In start-factory.sh after QEMU starts:
[ -f "${PID_FILE}" ] && sudo chown ${USER}:${USER} "${PID_FILE}"
```

### Issue 2: Docker Status Check User

**Problem:**
- Status script used `ssh root@localhost "docker ps"`
- But SSH key is for foreman user, not root
- Docker runs as foreman user with sudo access

**Why This Matters:**
```bash
# Docker socket ownership in VM:
ls -la /var/run/docker.sock
# srw-rw---- root docker docker.sock

# Foreman group membership:
id foreman
# uid=1000(foreman) gid=1000(foreman) groups=10(wheel),992(docker)

# So foreman can access Docker with sudo
```

**Solution:**
```bash
# Changed from:
ssh root@localhost "docker ps"

# To:
ssh foreman@localhost "sudo docker ps"
```

### Issue 3: MOTD Shell Compatibility

**Problem:**
- Alpine Linux uses `ash` (Almquist shell) as default
- MOTD script uses bash function syntax
- SSH executes commands with default shell (ash)
- Bash functions don't work in ash

**Why This Matters:**
```bash
# In ash (Alpine default):
function test() { echo "hello"; }
# ash: syntax error: unexpected "("

# In bash:
function test() { echo "hello"; }
# OK
```

**Solution:**
```bash
# Force bash shell:
ssh root@localhost 'bash -s' << 'MOTD_SCRIPT'
```

---

## What Works Now

### After Manual Fixes (Current VM)
‚úÖ Status script works: `~/vms/factory/status-factory.sh`  
‚úÖ Shows VM running with correct PID  
‚úÖ Shows Docker containers (Jenkins)  
‚úÖ Shows SSH and HTTPS status  
‚úÖ Shows VM resources (memory, disk)

### Example Output
```
Factory VM Status
=================

‚úì VM is running
  PID: 3062025

SSH (port 2222): ‚úì accessible
  Connection: working
HTTPS (port 443): ‚úì forwarded
  Jenkins: responding

Services:
  SSH:     ssh factory
  Jenkins: https://factory.local

VM Resources:
  Memory: 778.7M used / 7.7G total
  Disk:   2.1G used / 44.5G total (5% full)

Docker Containers:
  NAMES            STATUS
  jenkins-factory  Up 45 minutes
```

---

## Next Steps

### Critical: Fresh Installation Test

**Purpose:** Verify all fixes work in automated installation (no manual intervention)

**Procedure:**
```bash
# 1. Stop and remove current VM
~/vms/factory/stop-factory.sh
sudo pkill -9 qemu-system-aarch64  # If stop script fails
rm -rf ~/vms/factory/
rm -rf ~/.factory-vm/

# 2. Run fresh installation
cd ~/wip/nb/FinTechProj/factory-vm
./setup-factory-vm.sh 2>&1 | tee ~/logs/factory-vm-test-$(date +%Y%m%d-%H%M%S).log

# 3. Immediately test (while fresh)
~/vms/factory/status-factory.sh

# 4. Verify PID file ownership
ls -la ~/vms/factory/factory.pid
# Should show: -rw-r--r-- jcgarcia jcgarcia

# 5. Check MOTD
ssh factory
# Should display welcome banner

# 6. Check installation log for warnings
grep -i "warn\|fail\|error" ~/logs/factory-vm-test-*.log
```

**Expected Results:**
- [ ] No warnings during installation
- [ ] PID file owned by user (not root)
- [ ] Status script works immediately (no manual fixes)
- [ ] Docker containers visible in status
- [ ] MOTD displays on SSH
- [ ] All generated scripts have latest fixes

### Validation Checklist
- [ ] Run status script ‚Üí should work perfectly
- [ ] Check PID file ownership ‚Üí user:user
- [ ] SSH to VM ‚Üí MOTD displays
- [ ] Docker status ‚Üí shows Jenkins container
- [ ] Test Jenkins CLI ‚Üí authentication works
- [ ] Test Jenkins Web UI ‚Üí https://factory.local accessible
- [ ] Review installation log ‚Üí no errors/warnings

### If Test Fails
1. Save installation log
2. Check which component failed
3. Review generated scripts (start, status)
4. Compare with fixed source in setup-factory-vm.sh
5. Identify if timing issue or logic error
6. Apply additional fixes and retest

### If Test Succeeds
1. Document success in Sprint 2 status
2. Update CURRENT-STATUS.md
3. Proceed with Sprint 2 original goals:
   - Jenkins port forwarding verification
   - AWS SSO login testing
   - Full VM lifecycle testing
   - Documentation updates

---

## Commands Reference

### Check Current VM Status
```bash
~/vms/factory/status-factory.sh
ps aux | grep qemu
ssh factory 'docker ps'
jenkins-factory who-am-i
```

### View Installation Log
```bash
cat ~/logs/factory-vm-install-20251118-205730.log | less
grep -i error ~/logs/factory-vm-install-*.log
grep -i warn ~/logs/factory-vm-install-*.log
```

### Stop Current VM
```bash
~/vms/factory/stop-factory.sh
# Or force:
sudo pkill -9 qemu-system-aarch64
```

### Clean Everything
```bash
rm -rf ~/vms/factory/
rm -rf ~/.factory-vm/
rm ~/.jenkins-factory-token
rm ~/jenkins-cli-factory.jar
```

---

## Important Context for Next Session

### Git Status
```
Commit: e8da79ebb
Branch: aws (or main, check with: git branch)
Modified: factory-vm/setup-factory-vm.sh (49 insertions, 14 deletions)
Status: All changes committed
```

### Log Files Location
```
~/logs/factory-vm-install-20251118-205730.log  (current installation)
~/logs/                                         (all logs)
```

### Current VM Details
```
PID: 3062025
SSH Port: 2222
HTTPS Port: 443 (forwarded)
Memory: 8GB
CPUs: 6
Disk: 50GB system + 200GB data
Profile: High Performance
```

### Passwords
```
Jenkins Admin: admin / admin123
Jenkins Foreman: foreman / foreman123
Jenkins API Token: 11ce90a73ba75b661dbb5f3302227893e6
VM Foreman: SSH key auth (no password)
VM Root: SSH key auth (no password)

All stored in: ~/.factory-vm/credentials.txt
```

### SSH Access
```bash
ssh -p 2222 foreman@localhost
# Or with alias:
ssh factory

# Root access:
ssh -p 2222 root@localhost
```

### Jenkins Access
```bash
# Web UI:
https://factory.local

# CLI:
jenkins-factory who-am-i
jenkins-factory list-jobs
jenkins-factory help
```

---

## Lessons Learned

### 1. Test Timing Matters
Installing while making fixes ‚Üí generated files have old code  
**Solution:** Always test with fresh installation after committing fixes

### 2. Root Ownership Cascade
Sudo command ‚Üí root-owned files ‚Üí permission issues  
**Solution:** Plan for ownership fixes after sudo operations

### 3. Shell Portability
Alpine ‚â† Ubuntu, ash ‚â† bash  
**Solution:** Explicitly specify shell when needed (`bash -s`)

### 4. Defensive Coding
`set -euo pipefail` is strict ‚Üí undefined variables cause exit  
**Solution:** Use `${VAR:-default}` for all optional variables

### 5. Installation Logging
Critical for debugging post-mortem  
**Solution:** Always log to ~/logs/ with timestamps

---

## Files to Review Next Session

### Modified in This Session
```
factory-vm/setup-factory-vm.sh
factory-vm/CURRENT-STATUS.md
docs/milestones/FactoryVM-Sprint2-Status-Nov18.md
factory-vm/SESSION-CONTEXT-Nov18-2140.md (this file)
```

### Generated by Current Installation
```
~/vms/factory/start-factory.sh       (OLD - needs replacement)
~/vms/factory/status-factory.sh      (UPDATED manually)
~/vms/factory/stop-factory.sh        (OK)
~/.factory-vm/credentials.txt        (OK)
```

### Logs
```
~/logs/factory-vm-install-20251118-205730.log
```

---

## Open Questions

1. Should we add health check endpoint for VM status?
2. Should PID file location be configurable?
3. Should we add automatic fix for stale PID files?
4. Should status script auto-refresh if PID file is missing?
5. Should we add VM monitoring (resource usage over time)?

---

## Summary for Resume

**Current State:**
- Bug fixes committed ‚úÖ
- Current VM running but has manual fixes ‚ö†Ô∏è
- Ready for fresh installation test üî¥

**Immediate Action:**
Run fresh installation to verify automated fixes work

**Success Criteria:**
- Status script works immediately (no sudo, no manual fixes)
- Docker containers visible in status
- MOTD displays on SSH
- No warnings in installation log

**Then:**
Resume Sprint 2 tasks (Jenkins verification, AWS testing)

---

**End of Session Context**
